{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffd7bb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDueqOJ_1Clm8a6_kC-7E2IcCeSGB0H7Xk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2084cb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created successfully with 11 documents.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "with open('dataset.json', 'r', encoding='utf-8') as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "embedding_model = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/text-embedding-004\"\n",
    ")\n",
    "\n",
    "documents = []\n",
    "for item in dataset:\n",
    "    page_content = (\n",
    "    f\"Feature Name: {item['feature_name']}\\n\"\n",
    "    f\"Description: {item['description']}\\n\"\n",
    "    f\"Product Category: {item['product_category']}\\n\"\n",
    "    f\"Keywords: {', '.join(item['keywords'])}\\n\"\n",
    "    f\"Pain Points Solved: {', '.join(item['pain_points_solved'])}\\n\"\n",
    "    f\"Feature Type: {item['feature_type']}\\n\"\n",
    "    f\"Solution Phase: {item['solution_phase']}\\n\"\n",
    "    f\"Outputs: {', '.join(item['outputs_data_type'])}\\n\"\n",
    "    f\"Consumes: {', '.join(item['consumes_data_type'])}\\n\"\n",
    "    f\"Complements: {', '.join(item['complements_features'])}\\n\"\n",
    "    f\"Synergy: {item['synergy_description']}\"\n",
    ")\n",
    "\n",
    "    metadata = {\n",
    "        \"feature_id\": item[\"feature_id\"],\n",
    "        \"feature_name\": item[\"feature_name\"]\n",
    "    }\n",
    "\n",
    "    documents.append(Document(\n",
    "        page_content=page_content,\n",
    "        metadata=metadata\n",
    "    ))\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={\"k\": 3}\n",
    ")\n",
    "\n",
    "print(f\"Vector store created successfully with {len(documents)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c42dc60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='dacb91aa-11da-4c0f-9499-3bf4a7853fbd', metadata={'feature_name': 'VoC - Surveys', 'feature_id': 'VOC_SURVEYS'}, page_content=\"Feature Name: VoC - Surveys\\nDescription: Design and deploy surveys across Web, Mobile, Zalo, SMS, Email, QR, POS to collect customer feedback.\\nProduct Category: Voice of Customer (VoC)\\nKeywords: collect feedback, survey, customer opinion, NPS, CSAT, post-purchase\\nPain Points Solved: struggling to collect feedback, low survey response rate, don't know what customers think after purchase, manual feedback collection\\nFeature Type: Data_Collection\\nSolution Phase: Collect\\nOutputs: customer_feedback_raw, satisfaction_score\\nConsumes: customer_transaction_event, customer_segment\\nComplements: INSIGHTS_EXPERIENCE, CUSTOMER_360_CUSTOMERS\\nSynergy: Provides the raw data for 'Insights - Experience' to analyze, and can be targeted to specific segments from 'Customer 360'.\"),\n",
       " Document(id='a83eea54-aaa7-44f9-955d-b5021ee18038', metadata={'feature_name': 'VoC - Surveys', 'feature_id': 'VOC_SURVEYS'}, page_content=\"Feature Name: VoC - Surveys\\nDescription: Design and deploy surveys across Web, Mobile, Zalo, SMS, Email, QR, POS to collect customer feedback.\\nProduct Category: Voice of Customer (VoC)\\nKeywords: collect feedback, survey, customer opinion, NPS, CSAT, post-purchase\\nPain Points Solved: struggling to collect feedback, low survey response rate, don't know what customers think after purchase, manual feedback collection\\nFeature Type: Data_Collection\\nSolution Phase: Collect\\nOutputs: customer_feedback_raw, satisfaction_score\\nConsumes: customer_transaction_event, customer_segment\\nComplements: INSIGHTS_EXPERIENCE, CUSTOMER_360_CUSTOMERS\\nSynergy: Provides the raw data for 'Insights - Experience' to analyze, and can be targeted to specific segments from 'Customer 360'.\"),\n",
       " Document(id='865eb2e9-4637-49be-b622-7322edc91ef6', metadata={'feature_name': 'VoC - Reviews', 'feature_id': 'VOC_REVIEWS'}, page_content=\"Feature Name: VoC - Reviews\\nDescription: Aggregate and analyze reviews from various public platforms like Google, social media, and e-commerce sites in one dashboard.\\nProduct Category: Voice of Customer (VoC)\\nKeywords: online reviews, reputation management, sentiment analysis, product feedback, social listening\\nPain Points Solved: overwhelmed by reviews on many sites, don't know our public reputation, manually tracking competitor reviews, negative reviews are not handled promptly\\nFeature Type: Data_Collection\\nSolution Phase: Collect\\nOutputs: aggregated_reviews, review_sentiment\\nConsumes: \\nComplements: INSIGHTS_EXPERIENCE, SERVICE_TICKETS\\nSynergy: Gathers public reviews for analysis in 'Insights - Experience'. Negative reviews can automatically create a ticket for follow-up.\")]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"How to know if a feature is useful?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f628cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Dict, List, Any\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "def deconstruct_pain_point(pain_point_text: str) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Deconstructs pain point text into current problems and desired outcomes using an LLM.\n",
    "    \n",
    "    Args:\n",
    "        pain_point_text: User's description of their pain points\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with 'current_problems' and 'desired_outcomes' lists\n",
    "    \"\"\"\n",
    "    # Initialize the LLM with safety settings and JSON output enforcement\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-1.5-flash-latest\",\n",
    "        temperature=0.1,\n",
    "        convert_system_message_to_human=True\n",
    "    )\n",
    "    \n",
    "    # Define the structured output parser\n",
    "    parser = JsonOutputParser(pydantic_object=None)\n",
    "    \n",
    "    # Create the prompt template\n",
    "    prompt_template = ChatPromptTemplate.from_template(\n",
    "        \"Analyze the following customer pain point description and extract:\\n\"\n",
    "        \"1. CURRENT problems the user is experiencing (list of strings)\\n\"\n",
    "        \"2. DESIRED outcomes they want to achieve (list of strings)\\n\\n\"\n",
    "        \"Format output as JSON with exactly these keys: 'current_problems', 'desired_outcomes'\\n\\n\"\n",
    "        \"Pain point description: {pain_point}\\n\\n\"\n",
    "        \"Guidelines:\\n\"\n",
    "        \"- Return empty lists if no relevant items found\\n\"\n",
    "        \"- Never add explanations or additional text\\n\"\n",
    "        \"- Keep items concise (3-5 words each)\\n\"\n",
    "        \"- Extract verbatim phrases when possible\\n\"\n",
    "    )\n",
    "    \n",
    "    # Create and execute the processing chain\n",
    "    chain = prompt_template | llm | parser\n",
    "    try:\n",
    "        result = chain.invoke({\"pain_point\": pain_point_text})\n",
    "        # Validate the result structure\n",
    "        if not all(key in result for key in [\"current_problems\", \"desired_outcomes\"]):\n",
    "            raise ValueError(\"Invalid output structure from LLM\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        # Fallback to empty structure on error\n",
    "        return {\"current_problems\": [], \"desired_outcomes\": []}\n",
    "\n",
    "def match_features_to_pain_points(\n",
    "    deconstructed: Dict[str, List[str]], \n",
    "    retriever: BaseRetriever\n",
    ") -> Dict[str, List[Dict[str, str]]]:\n",
    "    \"\"\"\n",
    "    Matches problems and outcomes to product features using semantic search\n",
    "    \n",
    "    Args:\n",
    "        deconstructed: Output from deconstruct_pain_point\n",
    "        retriever: Vector store retriever instance\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary where keys are problems/outcomes and values are feature matches\n",
    "    \"\"\"\n",
    "    # Combine all problems and outcomes\n",
    "    all_terms = deconstructed[\"current_problems\"] + deconstructed[\"desired_outcomes\"][:1]\n",
    "    results = {}\n",
    "    \n",
    "    for term in all_terms:\n",
    "        try:\n",
    "            # Retrieve relevant documents\n",
    "            docs = retriever.get_relevant_documents(term)\n",
    "            matches = []\n",
    "            for doc in docs:\n",
    "                matches.append({\n",
    "                    \"feature_name\": doc.metadata[\"feature_name\"],\n",
    "                    \"feature_id\": doc.metadata[\"feature_id\"],\n",
    "                    \"score_context\": doc.page_content  # The full document content\n",
    "                })\n",
    "            results[term] = matches\n",
    "        except Exception as e:\n",
    "            # Continue processing other terms on error\n",
    "            results[term] = []\n",
    "            continue\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44a1a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "def select_best_feature(\n",
    "    pain_point_text: str,\n",
    "    deconstructed: Dict[str, List[str]],\n",
    "    matches: Dict[str, List[Dict[str, str]]],\n",
    "    max_candidates: int = 10\n",
    ") -> Optional[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Selects the best feature that addresses the overall pain point.\n",
    "    \n",
    "    Args:\n",
    "        pain_point_text: Original pain point description\n",
    "        deconstructed: Output from deconstruct_pain_point\n",
    "        matches: Output from match_features_to_pain_points\n",
    "        max_candidates: Maximum features to consider\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with best feature details and reasoning, or None if no matches\n",
    "    \"\"\"\n",
    "    # Collect all unique features from matches\n",
    "    seen_features = set()\n",
    "    candidate_features = []\n",
    "    \n",
    "    for term, feature_list in matches.items():\n",
    "        for feature in feature_list:\n",
    "            if feature[\"feature_id\"] not in seen_features:\n",
    "                seen_features.add(feature[\"feature_id\"])\n",
    "                candidate_features.append({\n",
    "                    \"feature_id\": feature[\"feature_id\"],\n",
    "                    \"feature_name\": feature[\"feature_name\"],\n",
    "                    \"context\": feature[\"score_context\"]\n",
    "                })\n",
    "                # Limit number of candidates\n",
    "                if len(candidate_features) >= max_candidates:\n",
    "                    break\n",
    "    \n",
    "    if not candidate_features:\n",
    "        return None\n",
    "    \n",
    "    # Prepare LLM for decision making\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-1.5-flash-latest\",\n",
    "        temperature=0.2,\n",
    "        convert_system_message_to_human=True\n",
    "    )\n",
    "    \n",
    "    # Format candidate features for prompt\n",
    "    candidates_str = \"\\n\\n\".join([\n",
    "        f\"Feature ID: {c['feature_id']}\\n\"\n",
    "        f\"Name: {c['feature_name']}\\n\"\n",
    "        f\"Details:\\n{c['context']}\"\n",
    "        for c in candidate_features\n",
    "    ])\n",
    "    \n",
    "    # Create decision-making prompt\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"As a product recommendation expert, select the single best feature that addresses \"\n",
    "        \"the customer's overall pain point. Consider both current problems and desired outcomes.\\n\\n\"\n",
    "        \"**Customer Pain Point**:\\n{pain_point}\\n\\n\"\n",
    "        \"**Key Elements**:\\n\"\n",
    "        \"- Current Problems: {current_problems}\\n\"\n",
    "        \"- Desired Outcomes: {desired_outcomes}\\n\\n\"\n",
    "        \"**Candidate Features**:\\n{candidates}\\n\\n\"\n",
    "        \"**Instructions**:\\n\"\n",
    "        \"1. Choose ONE feature that best solves the overall situation\\n\"\n",
    "        \"2. Consider comprehensiveness, relevance, and impact\\n\"\n",
    "        \"3. Output JSON with: 'feature_id', 'feature_name', and 'reason'\\n\"\n",
    "        \"4. 'reason' should be a concise 1-2 sentence explanation\\n\"\n",
    "        \"5. If no good match exists, set feature_id to null\\n\\n\"\n",
    "        \"Output ONLY valid JSON. Example:\\n\"\n",
    "        \"{{\\\"feature_id\\\": \\\"F123\\\", \\\"feature_name\\\": \\\"Smart Routing\\\", \\\"reason\\\": \\\"Explanation...\\\"}}\"\n",
    "    )\n",
    "    \n",
    "    # Create and execute the chain\n",
    "    chain = prompt | llm | JsonOutputParser()\n",
    "    \n",
    "    try:\n",
    "        result = chain.invoke({\n",
    "            \"pain_point\": pain_point_text,\n",
    "            \"current_problems\": \", \".join(deconstructed.get(\"current_problems\", []) or \"None identified\"),\n",
    "            \"desired_outcomes\": \", \".join(deconstructed.get(\"desired_outcomes\", []) or \"No specific goals\"),\n",
    "            \"candidates\": candidates_str\n",
    "        })\n",
    "        # Handle null selection\n",
    "        if not result.get(\"feature_id\"):\n",
    "            return None\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        # Log error in production (placeholder)\n",
    "        print(f\"Feature selection error: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4055c1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_outcomes(\n",
    "    current_problems: List[str],\n",
    "    desired_outcomes: List[str],\n",
    "    best_feature: Dict[str, Any],\n",
    "    retriever: BaseRetriever,\n",
    "    find_additional_features: bool = True  # Thêm parameter mới\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluates whether the recommended feature resolves current problems and achieves desired outcomes.\n",
    "    Also finds additional features for unresolved issues.\n",
    "    \n",
    "    Args:\n",
    "        current_problems: List of current problems from pain point analysis\n",
    "        desired_outcomes: List of desired outcomes from pain point analysis\n",
    "        best_feature: Dictionary containing selected feature details (from select_best_feature)\n",
    "        retriever: Vector store retriever for feature context\n",
    "        find_additional_features: Whether to find additional features for unresolved issues\n",
    "        \n",
    "    Returns:\n",
    "        Evaluation results with resolution status and additional features for unresolved issues\n",
    "    \"\"\"\n",
    "    # Handle case where no feature was recommended\n",
    "    if best_feature is None:\n",
    "        return {\n",
    "            \"overall_status\": \"no_feature_recommended\",\n",
    "            \"problem_resolution\": [{\"problem\": p, \"status\": \"not_resolved\"} for p in current_problems],\n",
    "            \"outcome_achievement\": [{\"outcome\": o, \"status\": \"not_achieved\"} for o in desired_outcomes],\n",
    "            \"resolved_items\": {\n",
    "                \"problems\": [],\n",
    "                \"outcomes\": [],\n",
    "                \"unresolved_items\": [\n",
    "                    {\"item\": p, \"type\": \"problem\", \"status\": \"not_resolved\"} for p in current_problems\n",
    "                ] + [\n",
    "                    {\"item\": o, \"type\": \"outcome\", \"status\": \"not_achieved\"} for o in desired_outcomes\n",
    "                ]\n",
    "            },\n",
    "            \"additional_features\": {}\n",
    "        }\n",
    "\n",
    "    # Get full feature context\n",
    "    feature_id = best_feature[\"feature_id\"]\n",
    "    try:\n",
    "        docs = retriever.get_relevant_documents(f\"Feature ID: {feature_id}\")\n",
    "        feature_context = docs[0].page_content if docs else \"No context available\"\n",
    "    except Exception:\n",
    "        feature_context = \"No context available\"\n",
    "\n",
    "    # Prepare LLM for evaluation\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-1.5-flash-latest\",\n",
    "        temperature=0,\n",
    "        convert_system_message_to_human=True\n",
    "    )\n",
    "    \n",
    "    # Create evaluation prompt\n",
    "    prompt_template = ChatPromptTemplate.from_template(\n",
    "        \"EVALUATE how well the recommended feature addresses the user's problems and desired outcomes.\\n\\n\"\n",
    "        \"**Recommended Feature**\\n\"\n",
    "        \"ID: {feature_id}\\n\"\n",
    "        \"Name: {feature_name}\\n\"\n",
    "        \"Details:\\n{feature_context}\\n\\n\"\n",
    "        \"**User's Current Problems**\\n{problems}\\n\\n\"\n",
    "        \"**User's Desired Outcomes**\\n{outcomes}\\n\\n\"\n",
    "        \"**Evaluation Tasks**\\n\"\n",
    "        \"1. For EACH current problem:\\n\"\n",
    "        \"   - Determine if feature Does or DOES NOT resolve it\\n\"\n",
    "        \"   - Provide 1-sentence technical justification\\n\"\n",
    "        \"2. For EACH desired outcome:\\n\"\n",
    "        \"   - Determine if feature DOES or DOES NOT achieve it\\n\"\n",
    "        \"   - Provide 1-sentence technical justification\\n\"\n",
    "        \"3. Give overall resolution status\\n\\n\"\n",
    "        \"**Output Format**\\n\"\n",
    "        \"{{\"\n",
    "        \"\\\"overall_status\\\": \\\"resolved\\\"  | \\\"not_resolved\\\",\"\n",
    "        \"\\\"problem_resolution\\\": [\"\n",
    "        \"   {{\\\"problem\\\": \\\"text\\\", \\\"status\\\": \\\"resolved\\\"  | \\\"not_resolved\\\", \\\"reason\\\": \\\"explanation\\\"}}\"\n",
    "        \"],\"\n",
    "        \"\\\"outcome_achievement\\\": [\"\n",
    "        \"   {{\\\"outcome\\\": \\\"text\\\", \\\"status\\\": \\\"achieved\\\"  | \\\"not_achieved\\\", \\\"reason\\\": \\\"explanation\\\"}}\"\n",
    "        \"]}}\"\n",
    "    )\n",
    "    \n",
    "    # Build and execute chain\n",
    "    chain = prompt_template | llm | JsonOutputParser()\n",
    "    \n",
    "    try:\n",
    "        result = chain.invoke({\n",
    "            \"feature_id\": feature_id,\n",
    "            \"feature_name\": best_feature[\"feature_name\"],\n",
    "            \"feature_context\": feature_context,\n",
    "            \"problems\": \"\\n- \".join(current_problems),\n",
    "            \"outcomes\": \"\\n- \".join(desired_outcomes)\n",
    "        })\n",
    "        \n",
    "        # Thêm logic đánh dấu resolved items\n",
    "        resolved_items = {\n",
    "            \"problems\": [],\n",
    "            \"outcomes\": [],\n",
    "            \"unresolved_items\": []\n",
    "        }\n",
    "        \n",
    "        # Đánh dấu problems\n",
    "        if \"problem_resolution\" in result:\n",
    "            for problem_item in result[\"problem_resolution\"]:\n",
    "                if problem_item.get(\"status\") == \"resolved\":\n",
    "                    resolved_items[\"problems\"].append({\n",
    "                        \"item\": problem_item[\"problem\"],\n",
    "                        \"status\": \"resolved\",\n",
    "                        \"reason\": problem_item.get(\"reason\", \"Successfully addressed\")\n",
    "                    })\n",
    "                else:\n",
    "                    resolved_items[\"unresolved_items\"].append({\n",
    "                        \"item\": problem_item[\"problem\"],\n",
    "                        \"type\": \"problem\",\n",
    "                        \"status\": problem_item.get(\"status\", \"not_resolved\"),\n",
    "                        \"reason\": problem_item.get(\"reason\", \"Not addressed\")\n",
    "                    })\n",
    "        \n",
    "        # Đánh dấu outcomes\n",
    "        if \"outcome_achievement\" in result:\n",
    "            for outcome_item in result[\"outcome_achievement\"]:\n",
    "                if outcome_item.get(\"status\") == \"achieved\":\n",
    "                    resolved_items[\"outcomes\"].append({\n",
    "                        \"item\": outcome_item[\"outcome\"],\n",
    "                        \"status\": \"achieved\",\n",
    "                        \"reason\": outcome_item.get(\"reason\", \"Successfully achieved\")\n",
    "                    })\n",
    "                else:\n",
    "                    resolved_items[\"unresolved_items\"].append({\n",
    "                        \"item\": outcome_item[\"outcome\"],\n",
    "                        \"type\": \"outcome\",\n",
    "                        \"status\": outcome_item.get(\"status\", \"not_achieved\"),\n",
    "                        \"reason\": outcome_item.get(\"reason\", \"Not achieved\")\n",
    "                    })\n",
    "        \n",
    "        # Tìm additional features cho unresolved items nếu được yêu cầu\n",
    "        additional_features = {}\n",
    "        if find_additional_features and resolved_items[\"unresolved_items\"]:\n",
    "            for unresolved_item in resolved_items[\"unresolved_items\"]:\n",
    "                item_text = unresolved_item[\"item\"]\n",
    "                try:\n",
    "                    docs = retriever.get_relevant_documents(item_text)\n",
    "                    matches = []\n",
    "                    for doc in docs:\n",
    "                        matches.append({\n",
    "                            \"feature_id\": doc.metadata[\"feature_id\"],\n",
    "                            \"feature_name\": doc.metadata[\"feature_name\"],\n",
    "                            \"relevance_score\": \"high\" if item_text.lower() in doc.page_content.lower() else \"medium\",\n",
    "                            \"context\": doc.page_content\n",
    "                        })\n",
    "                    additional_features[f\"{unresolved_item['type']}_{item_text}\"] = matches\n",
    "                except Exception as e:\n",
    "                    additional_features[f\"{unresolved_item['type']}_{item_text}\"] = []\n",
    "        \n",
    "        # Thêm thông tin mới vào result\n",
    "        result[\"resolved_items\"] = resolved_items\n",
    "        result[\"additional_features\"] = additional_features\n",
    "        result[\"summary\"] = {\n",
    "            \"total_unresolved\": len(resolved_items[\"unresolved_items\"]),\n",
    "            \"problems_resolved\": len(resolved_items[\"problems\"]),\n",
    "            \"outcomes_achieved\": len(resolved_items[\"outcomes\"]),\n",
    "            \"problems_unresolved\": len([item for item in resolved_items[\"unresolved_items\"] if item[\"type\"] == \"problem\"]),\n",
    "            \"outcomes_unachieved\": len([item for item in resolved_items[\"unresolved_items\"] if item[\"type\"] == \"outcome\"])\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Fallback evaluation\n",
    "        return {\n",
    "            \"overall_status\": \"evaluation_failed\",\n",
    "            \"problem_resolution\": [{\"problem\": p, \"status\": \"unknown\"} for p in current_problems],\n",
    "            \"outcome_achievement\": [{\"outcome\": o, \"status\": \"unknown\"} for o in desired_outcomes],\n",
    "            \"resolved_items\": {\n",
    "                \"problems\": [],\n",
    "                \"outcomes\": [],\n",
    "                \"unresolved_items\": [\n",
    "                    {\"item\": p, \"type\": \"problem\", \"status\": \"unknown\"} for p in current_problems\n",
    "                ] + [\n",
    "                    {\"item\": o, \"type\": \"outcome\", \"status\": \"unknown\"} for o in desired_outcomes\n",
    "                ]\n",
    "            },\n",
    "            \"additional_features\": {},\n",
    "            \"summary\": {\n",
    "                \"total_unresolved\": len(current_problems) + len(desired_outcomes),\n",
    "                \"problems_resolved\": 0,\n",
    "                \"outcomes_achieved\": 0,\n",
    "                \"problems_unresolved\": len(current_problems),\n",
    "                \"outcomes_unachieved\": len(desired_outcomes)\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13dc1b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:499: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'current_problems': ['overwhelmed support agents',\n",
       "  'high volume questions',\n",
       "  'repetitive questions'],\n",
       " 'desired_outcomes': ['automate responses', 'automate common queries']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full workflow example\n",
    "pain_point = \"Our support agents are overwhelmed by the high volume of repetitive questions and i want to automate responses to common queries.\"\n",
    "# Stage 1: Deconstruct pain point\n",
    "deconstructed = deconstruct_pain_point(pain_point)\n",
    "deconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "402fddca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deconstructed pain point: {'current_problems': ['overwhelmed support agents', 'high volume questions', 'repetitive questions'], 'desired_outcomes': ['automate responses', 'automate common queries']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:499: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'feature_id': 'SERVICE_AI_INBOX',\n",
       " 'feature_name': 'AI Customer Service - AI Inbox',\n",
       " 'reason': 'This feature directly addresses the high volume of repetitive questions by enabling AI-assisted responses, thus alleviating the burden on support agents and improving response times.  Its omnichannel capabilities further enhance efficiency.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Deconstructed pain point: {deconstructed}\")\n",
    "# Stage 2: Match features to pain point components\n",
    "matches = match_features_to_pain_points(deconstructed, retriever)\n",
    "matches\n",
    "# Stage 3: Select best overall feature\n",
    "best_feature = select_best_feature(\n",
    "    pain_point_text=pain_point,\n",
    "    deconstructed=deconstructed,\n",
    "    matches=matches\n",
    ")\n",
    "best_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71629cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:499: UserWarning: Convert_system_message_to_human will be deprecated!\n",
      "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'overall_status': 'partially_resolved',\n",
       " 'problem_resolution': [{'problem': 'overwhelmed support agents - high volume questions',\n",
       "   'status': 'partially_resolved',\n",
       "   'reason': \"The AI agent can handle some of the high volume questions, reducing the load on human agents, but it doesn't eliminate the high volume entirely.\"},\n",
       "  {'problem': 'overwhelmed support agents - repetitive questions',\n",
       "   'status': 'resolved',\n",
       "   'reason': 'The AI agent can be trained to automatically answer repetitive questions, freeing up human agents to focus on more complex issues.'}],\n",
       " 'outcome_achievement': [{'outcome': 'automate responses - automate common queries',\n",
       "   'status': 'achieved',\n",
       "   'reason': 'The AI agent within the omnichannel inbox is designed to automate responses to common queries, as described in the feature details.'}]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stage 4: Evaluate outcomes\n",
    "evaluation = evaluate_outcomes(\n",
    "    current_problems=deconstructed[\"current_problems\"],\n",
    "    desired_outcomes=deconstructed[\"desired_outcomes\"],\n",
    "    best_feature=best_feature,\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b014a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
